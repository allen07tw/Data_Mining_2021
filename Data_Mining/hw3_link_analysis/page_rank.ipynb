{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "graph_1_list = []\n",
    "graph_1_list_node_1 = []\n",
    "graph_2_list = []\n",
    "graph_2_list_node_1 = []\n",
    "graph_3_list = []\n",
    "graph_3_list_node_1 = []\n",
    "graph_4_list = []\n",
    "graph_5_list = []\n",
    "graph_6_list = []\n",
    "\n",
    "with open('graph_1.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_1_list.append(list(line.strip('\\n').split(',')))\n",
    "        \n",
    "with open('graph_1.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_1_list_node_1.append(list(line.strip('\\n').split(',')))\n",
    "    append_list_1 = [['2', '1'], ['1', '3'], ['1', '4'], ['1', '5'], ['1', '6'], ['3', '1'], ['4', '1'], ['5', '1'], ['6', '1']]\n",
    "    for edge in append_list_1:\n",
    "        graph_1_list_node_1.append(edge)\n",
    "with open('graph_2.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_2_list.append(list(line.strip('\\n').split(',')))\n",
    "        \n",
    "with open('graph_2.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_2_list_node_1.append(list(line.strip('\\n').split(',')))\n",
    "    append_list_2 = [['2', '1'], ['1', '3'], ['1', '4'], ['1', '5'], ['3', '1'], ['4', '1'], ['5', '1']]\n",
    "    for edge in append_list_2:\n",
    "        graph_2_list_node_1.append(edge)\n",
    "with open('graph_3.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_3_list.append(list(line.strip('\\n').split(',')))\n",
    "with open('graph_3.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_3_list_node_1.append(list(line.strip('\\n').split(',')))\n",
    "    append_list_3 = [['1', '3'], ['1', '4'], ['3', '1'], ['4', '1']]\n",
    "    for edge in append_list_3:\n",
    "        graph_3_list_node_1.append(edge)\n",
    "with open('graph_4.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_4_list.append(list(line.strip('\\n').split(',')))\n",
    "with open('graph_5.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_5_list.append(list(line.strip('\\n').split(',')))\n",
    "with open('graph_6.txt','r') as f:\n",
    "    for line in f:\n",
    "        graph_6_list.append(list(line.strip('\\n').split(',')))\n",
    "\n",
    "\n",
    "data_txt = np.loadtxt('IBM_testing_dataset.txt')\n",
    "IBM_testing_txtDF = pd.DataFrame(data_txt)\n",
    "IBM_data = []\n",
    "\n",
    "for IBM_item,customer in enumerate(IBM_testing_txtDF[0]):\n",
    "    if len(IBM_data) < int(customer):\n",
    "        IBM_data.append(list())\n",
    "        IBM_data[int(customer)-1].append(str(IBM_testing_txtDF[2][IBM_item]))\n",
    "    else:\n",
    "        IBM_data[int(customer)-1].append(str(IBM_testing_txtDF[2][IBM_item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association_Rules\n",
      "1088 rules generated\n",
      "FP_Growth_spent_time 0.3966660499572754\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import time\n",
    "\n",
    "IBM_data =pd.DataFrame(index=range(len(IBM_data)),data=IBM_data)\n",
    "#Read data from CSV\n",
    "# data = pd.read_csv('groceries.csv')\n",
    "data = IBM_data\n",
    "# data = pd.read_csv('Market_Basket_Optimisation.csv', header=None)\n",
    "#\n",
    "#Parameters\n",
    "minsup = 0.045#float(input(\"Support-Threshold: \"))\n",
    "minsup = minsup * len(data)\n",
    "minconf = 0.1#float(input(\"Confidence-Threshold: \"))\n",
    "# print(len(data))#9835\n",
    "time_start = time.time()\n",
    "\n",
    "#Add all data in a list of lists\n",
    "items = []  \n",
    "# print(len(data.values[0]))#1列(ROW)有32的物品\n",
    "for i in range(0, len(data)):  #將所有data中的物品一列一列放到items\n",
    "     items.append([str(data.values[i, j]) for j in range(0, len(data.values[0]))])\n",
    "\n",
    "#Creating a list of dictionaries\n",
    "count = [dict() for x in range(len(data.values[0]) + 1)]\n",
    "# print(items)\n",
    "# #Count support for each individual items\n",
    "s = []\n",
    "for i in items:\n",
    "    for j in i:      #讀取所有items\n",
    "        s.append(j)\n",
    "for i in s:                      #創字典 放在count[1]\n",
    "    #If item is present in dictionary, increment its count by 1\n",
    "    if i in count[1]:\n",
    "        count[1][i] = count[1][i] + 1\n",
    "    #If item is not present in dictionary, set its count to 1\n",
    "    else:\n",
    "        count[1][i] = 1     #{'i':1}\n",
    "\n",
    "# #Remove infrequent and empty items #去除小於minsup,nan\n",
    "for i in count[1].copy():\n",
    "    if(count[1][i] < minsup):\n",
    "        count[1].pop(i)\n",
    "# count[1].pop('nan') #去除以key = 'NAN'產生的值\n",
    "count[1].pop('None') #去除以key = 'NAN'產生的值\n",
    "\n",
    "# #Storing transactions as lists without infrequent items\n",
    "a = list(count[1]) #列出所有符合的KEY\n",
    "item = [list() for i in range(len(data))] #創造len(data) = 9835個list \n",
    "c = 0 \n",
    "for i in range(0,len(items)): ##將所有data中的物品一列一列放到items\n",
    "    for j in range(len(items[i])):\n",
    "#         print(items[i][j])\n",
    "        if(a.__contains__(items[i][j]) != 0): #確認物品是否存在\n",
    "            item[i].append(items[i][j]) #將物品分成[['a', 'b', 'c'],[]]與itmes不同的地方是裡練已經沒有NAN了\n",
    "\n",
    "#Function to sort list to support\n",
    "def sort(a): #a = 所有符合的KEY的list\n",
    "    for i in range(len(a) - 1):\n",
    "        for j in range(len(a) - i - 1):\n",
    "            if(count[1][a[j]] < count[1][a[j + 1]]): #如果下一個比上一個大則互換位子\n",
    "                a[j],a[j + 1] = a[j + 1],a[j]\n",
    "                \n",
    "#Call function to sort all transactions in descending order of their support\n",
    "for i in range(0,len(data)): #9835\n",
    "    if(len(item[i]) > 1): #如果不只一個物件就排序他\n",
    "        sort(item[i])\n",
    "\n",
    "#Tree class for FP-Tree\n",
    "class tree: #設計樹根，分支\n",
    "    def __init__(self, name, sup, parent):\n",
    "        self.name = name\n",
    "        self.sup = sup\n",
    "        self.nodeLink = None\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "\n",
    "#Function to check if the node is present is a child of the current node\n",
    "def ispresent(node,name):    #確認是否有children\n",
    "    f = -1               \n",
    "    for i in node.children:\n",
    "        f += 1\n",
    "        if(i.name == name):\n",
    "            return f\n",
    "    return -1\n",
    "\n",
    "#HeaderTable which stores the reference of last/first occurence of an item. Used as a linked list to generate candidate trees \n",
    "lastocc = count[1].copy() #符合sup的字典\n",
    "for i in lastocc: #lastocc字典中所有值皆為NONE\n",
    "    lastocc[i] = None\n",
    "#Function to create FP-tree\n",
    "root = tree(\"root\", -1, None)\n",
    "z = 0\n",
    "for i in item: #item為沒有NAN的items\n",
    "    current = root\n",
    "    for j in range(len(i)): #len(i)9835\n",
    "        if(ispresent(current,i[j]) >= 0): #第一次通常不符合此情形，直接執行else，看有沒有children\n",
    "            current = current.children[ispresent(current, i[j])]\n",
    "            current.sup = current.sup + 1\n",
    "        else:\n",
    "            child=tree(i[j], 1, current)    #創建i[j]子根\n",
    "            current.children.append(child) #將子根放入children =[] \n",
    "            t = current #t 記錄柱上一層的tree1\n",
    "            current = current.children[ispresent(current, i[j])] #現在current.children裡有子根，所以self.name = i[j]如下示意，\n",
    "            #ispresent(current,i[j])回傳 0 ，現在的current為tree2\n",
    "            current.parent = t #紀錄上一層tree1\n",
    "            if(lastocc[current.name] == None):\n",
    "                lastocc[current.name] = current #創建{'i[j]': tree2-1()} \n",
    "            else:#創出第一層並列樹枝\n",
    "                current.nodeLink = lastocc[current.name] #將tree2-2連結到tree4\n",
    "                lastocc[current.name] = current #CURRENT = TREE2-2 {'i[j]': tree2-2}\n",
    "            \n",
    "# class tree1:\n",
    "#     def __init__(self, name, sup, parent):\n",
    "#         self.name = 'root'\n",
    "#         self.sup = -1\n",
    "#         self.nodeLink = None\n",
    "#         self.parent = none\n",
    "#         self.children = [\n",
    "#   class tree2-1:\n",
    "#     def __init__(self, name, sup, parent):      [['A','B','C'],['C','A']]\n",
    "#         self.name = 'A'\n",
    "#         self.sup = 1\n",
    "#         self.nodeLink = NONE\n",
    "#         self.parent = parent\n",
    "#         self.children = [\n",
    "#                                     class tree3:\n",
    "#                                         def __init__(self, name, sup, parent):\n",
    "#                                             self.name = 'B'\n",
    "#                                             self.sup = 1\n",
    "#                                             self.nodeLink = None\n",
    "#                                             self.parent = parent\n",
    "#                                             self.children = [\n",
    "#                                                                 class tree4:\n",
    "#                                                                     def __init__(self, name, sup, parent):\n",
    "#                                                                         self.name = 'B'\n",
    "#                                                                         self.sup = 1\n",
    "#                                                                         self.nodeLink = None\n",
    "#                                                                         self.parent = parent\n",
    "#                                                                         self.children = []\n",
    "#                                                                 ]\n",
    "#         ],\n",
    "#   class tree2-2:\n",
    "#     def __init__(self, name, sup, parent):\n",
    "#         self.name = 'C'\n",
    "#         self.sup = sup\n",
    "#         self.nodeLink = TREE 4\n",
    "#         self.parent = TREE1\n",
    "#         self.children = []\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "#Function to get frequent itemsets with suffix 'node' and length n\n",
    "def singlepath(node, n):\n",
    "    c = 0\n",
    "    sup = node.sup\n",
    "    path = []\n",
    "    pathname = []\n",
    "    current = node\n",
    "    \n",
    "    #Get the path from current node to root\n",
    "    while(current.parent != None): #查看目current是否為'root'，如果是則無parent，重複做直道回到最上層('root')\n",
    "        path.append(current)     #將current內容紀錄(tree)\n",
    "        pathname.append(current.name)      #('c')\n",
    "        current = current.parent  #往上一層移動\n",
    "    path.remove(node) #除了自己以外的路線\n",
    "    pathname.remove(node.name) \n",
    "    candidatepath = []\n",
    "    temp_candidatepath = []\n",
    "   \n",
    "    #Generate combinations of length n in the path\n",
    "    a = (list(combinations(pathname, n))) #列出除了自己以外的長度為n的組合\n",
    "    for j in a:\n",
    "        temp_candidatepath.append(tuple(sorted(j)))   #以tuple形式存在temp_candidatapath裡\n",
    "    #Append the suffix 'node.name' to the above paths\n",
    "    for j in temp_candidatepath:\n",
    "        j = list(j) #再次變回list\n",
    "        j.append(node.name) #將原本剔除的當前TREE名加回去 變成包含當前的組合，就是在做freqent pattern\n",
    "        candidatepath.append(sorted(j)) #在加回去變成 [['a','c'],['b','c']]\n",
    "    #Update counts of the generated itemsets\n",
    "    for j in candidatepath:\n",
    "        j = tuple(j) #j = ('a','c')\n",
    "        if j in count[n + 1]: #count[1]為符合minsup的字典，n至少會從1開始 \n",
    "            count[n + 1][j] = count[n + 1][j] + sup  # 將之前已創好的value值，加上當前tree所有的sup\n",
    "        else:\n",
    "            count[n + 1][j] = sup #創建新字典,此sup為當前tree存有的sup\n",
    "            \n",
    "    #Iterating in the candidate tree recursively \n",
    "    if(node.nodeLink != None): #查看是否存在分支\n",
    "        node=node.nodeLink\n",
    "        singlepath(node, i) #i為組合長度\n",
    "    \n",
    "#Check if itemset is frequent\n",
    "def frequent(n): #算出現次數\n",
    "    f=0\n",
    "    for i in count[n]:\n",
    "        if(count[n][i] >= minsup):\n",
    "            f = 1\n",
    "    if(f == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Call singlepath function for all frequent nodes\n",
    "for i in range(1, len(data.values[0]) + 1): #1列(ROW)有32的物品, +1是確保有32為一組的組合  #!\n",
    "    if(frequent(i) == 1):\n",
    "        for j in lastocc: #開始製造組合，將結果放到count[]裡，count唯有32空字典的list\n",
    "            singlepath(lastocc[j], i)\n",
    "\n",
    "#Remove infrequent itemsets\n",
    "for z in range(len(data.values[0]) + 1):            \n",
    "    for i in count[z].copy():\n",
    "            if(count[z][i] < minsup): #查看所有的dict裡面的東西，是否符合minsup\n",
    "                count[z].pop(i) #去掉不符合的\n",
    "\n",
    "frequent_pattern = []\n",
    "for items in count:\n",
    "    for want in items:\n",
    "        frequent_pattern.append(want)\n",
    "                \n",
    "#Get 'q', the length of the longest itemset\n",
    "i=1 #設2是因為從第二筆的字典，才開始有東西\n",
    "while(len(count[i]) != 0): #從這邊就能知道最大符合長度是多長，因為不符合的都被刪掉了，所以count最大的子矩陣\n",
    "    i = i + 1\n",
    "q = i - 1\n",
    "\n",
    "#Find maximal and closed itemsets\n",
    "maximal = []\n",
    "closed = []\n",
    "for i in range(1, q):\n",
    "    for j in count[i]:\n",
    "        fm = 0\n",
    "        fc = 0\n",
    "        for k in count[i + 1]:\n",
    "            a = set(list([j]))\n",
    "            b = set(list(k))\n",
    "            #Set is maximal if no immediate superset is frequent\n",
    "            if(a.intersection(b) == a): #如果兩者重疊則maximal\n",
    "                fm = 1 \n",
    "                #Set is closed if none of its immediate supersets have equal support\n",
    "                if(count[i][j] == count[i + 1][k]): #出現次數相同\n",
    "                    fc = 1\n",
    "        if(fm == 0):\n",
    "            maximal.append(j)\n",
    "        if(fc == 0):\n",
    "            closed.append(j)\n",
    "#All sets at the top of the tree are automatically maximal and closed\n",
    "for i in count[q]:\n",
    "    maximal.append(i)\n",
    "    closed.append(i)\n",
    "    \n",
    "# print(\"frequent_pattern\")\n",
    "# print('number of frequent pattern',len(frequent_pattern))\n",
    "# print(frequent_pattern)\n",
    " \n",
    "#Find Association Rules \n",
    "print(\"Association_Rules\")\n",
    "all_frequent_pattern = {}\n",
    "for len_FP in count:\n",
    "    all_frequent_pattern.update(len_FP)\n",
    "\n",
    "IBM_list = []\n",
    "def rulegenerator(fitems): #fitmes = 最終dic\n",
    "    '''\n",
    "    Generates association rules from the frequent itemsets\n",
    "    '''\n",
    "    counter = 0\n",
    "    \n",
    "    for itemset in fitems.keys():\n",
    "        if isinstance(itemset, str): #只有單個得我不要，我要tuple形式('a','b')\n",
    "            continue\n",
    "        length = len(itemset)#tuple裡面有幾項\n",
    "        union_support = fitems[tuple(itemset)]#原本itemset為LIST形式，必須使用tuple(才可以變成key ，看兩個以上的品項的出現次數\n",
    "        for i in range(1, length):\n",
    "            lefts = map(list, combinations(itemset, i)) #['mineral water'], ['pancakes']\n",
    "            for left in lefts:\n",
    "                if len(left) == 1:\n",
    "                    if ''.join(left) in fitems:\n",
    "                        leftcount = fitems[''.join(left)]#單品項出現次數 \n",
    "                        conf = union_support / leftcount\n",
    "                y_list = []\n",
    "                x_list = []\n",
    "                if conf >= minconf:\n",
    "                    right = list(itemset[:])\n",
    "                    sub_list = []\n",
    "                    for e in left:                          #去除被分配在左邊的品項\n",
    "                        right.remove(e)     \n",
    "#                     fo.write(str(left) + ' (' + str(leftcount) + ')' + ' -> ' + str(right) + ' (' + str(fitems[''.join(right)]) + ')' + ' [' + str(conf) + ']' + '\\n')\n",
    "                    \n",
    "                    \n",
    "#                     print(str(left) + ' -> ' + str(right) + ' (' + str(conf) + ')')\n",
    "#                     for y in left:\n",
    "#                         y_list.append(int(float(y)))\n",
    "#                     for x in right:\n",
    "#                         x_list.append(int(float(x)))\n",
    "                    for y in left:\n",
    "                        y_list.append(y)\n",
    "                    for x in right:\n",
    "                        x_list.append(x)\n",
    "                    sub_list.append(y_list)\n",
    "                    sub_list.append(x_list)\n",
    "                    IBM_list.append(sub_list)\n",
    "                    counter += 1\n",
    "#                     fo.close()\n",
    "    print(counter, \"rules generated\")\n",
    "\n",
    "rulegenerator(all_frequent_pattern)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_end = time.time()\n",
    "print('FP_Growth_spent_time', time_end - time_start)\n",
    "# print( time_end - time_start)\n",
    "# print(len(ant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "9.209645584854625e-05\n",
      "6\n",
      "[0.03480556 0.07599656 0.12474286 0.18241334 0.25064252 0.33139916]\n",
      "time cost 0.002385854721069336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_1_list\n",
    "Damping_factor = 0.15\n",
    "\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):#取零只是我想找len隨意設的\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) + (1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'D = {Damping_factor}')\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_1_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_1_power_node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "6.244088680754101e-05\n",
      "6\n",
      "[0.35987982 0.08617426 0.1228026  0.1383662  0.14498351 0.14779362]\n",
      "time cost 0.002293825149536133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_1_list_node_1\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):#取零只是我想找len隨意設的\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_1_PageRank_power_node_1_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.0\n",
      "5\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "time cost 0.004675149917602539\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_2_list\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_2_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_2_power_node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "6.558517908100692e-05\n",
      "5\n",
      "[0.37426656 0.10952468 0.15607922 0.17585877 0.18427078]\n",
      "time cost 0.003728151321411133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_2_list_node_1\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):#取零只是我想找len隨意設的\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_2_PageRank_power_node_1_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7.275616239243998e-05\n",
      "4\n",
      "[0.19908329 0.30091671 0.30091671 0.19908329]\n",
      "time cost 0.001787424087524414\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_3_list\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_3_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_3_power_node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "9.974359202091776e-05\n",
      "4\n",
      "[0.29522179 0.20477821 0.29522179 0.20477821]\n",
      "time cost 0.008326292037963867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_3_list_node_1\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):#取零只是我想找len隨意設的\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_3_PageRank_power_node_1_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "4.461390240563523e-05\n",
      "7\n",
      "[0.19846218 0.17338185 0.17220318 0.13250982 0.16827854 0.07305883\n",
      " 0.08210561]\n",
      "time cost 0.0044820308685302734\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_4_list\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_4_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "9.336569216016359e-05\n",
      "469\n",
      "[0.00021951 0.00021951 0.00021951 0.00021951 0.00021951 0.00026219\n",
      " 0.00026219 0.00026219 0.00026219 0.00026219 0.00026219 0.00026219\n",
      " 0.00026219 0.00026219 0.00026219 0.00027383 0.00027211 0.00038798\n",
      " 0.00028737 0.00037416 0.02233096 0.02233096 0.00037416 0.03196575\n",
      " 0.00033366 0.00027049 0.00028041 0.00027211 0.00027211 0.00029567\n",
      " 0.00028112 0.00027211 0.00031344 0.00029225 0.02226695 0.00040125\n",
      " 0.00027934 0.00030766 0.00037416 0.00186319 0.00027211 0.00037416\n",
      " 0.04954971 0.07201541 0.00027211 0.00075966 0.00035621 0.00036189\n",
      " 0.00027383 0.00036749 0.00027383 0.00027211 0.00027211 0.00040125\n",
      " 0.00054908 0.00027934 0.00027418 0.00036873 0.00027404 0.00062308\n",
      " 0.00813812 0.00027418 0.00034899 0.00027211 0.00033317 0.00027404\n",
      " 0.00037416 0.00027383 0.00027211 0.01461162 0.00042214 0.00029225\n",
      " 0.00027418 0.00027211 0.00030766 0.00027211 0.00027211 0.00030766\n",
      " 0.00029121 0.00027404 0.00054908 0.00037416 0.00037416 0.00040244\n",
      " 0.00033366 0.00027404 0.00027404 0.00042181 0.00031089 0.00027566\n",
      " 0.00037416 0.01745281 0.00027418 0.06029185 0.00030766 0.08924871\n",
      " 0.00027404 0.00037416 0.00027211 0.00027418 0.00037416 0.00027383\n",
      " 0.00027934 0.00573077 0.0003481  0.00028112 0.00027404 0.00027418\n",
      " 0.01461162 0.00037416 0.00037416 0.00030766 0.00029143 0.00055371\n",
      " 0.00030766 0.00055371 0.00027404 0.00036189 0.0003249  0.00027211\n",
      " 0.0003249  0.00802541 0.00027383 0.00039166 0.00030766 0.00036933\n",
      " 0.00027418 0.00045248 0.00027211 0.00093424 0.00028041 0.00037416\n",
      " 0.00047604 0.00231451 0.00045248 0.00065516 0.00306069 0.00027211\n",
      " 0.00027418 0.00027418 0.00119773 0.00087125 0.00048305 0.00037416\n",
      " 0.00027383 0.00027418 0.00045248 0.00280293 0.00027211 0.00027383\n",
      " 0.00027383 0.0427477  0.00028737 0.00064378 0.00030766 0.00029121\n",
      " 0.00029143 0.00027211 0.00032628 0.00075199 0.00027418 0.00027049\n",
      " 0.00037416 0.00065585 0.00027383 0.00055371 0.01553667 0.00031318\n",
      " 0.00037416 0.00027211 0.00045457 0.00028737 0.00027211 0.00045286\n",
      " 0.00027383 0.00030766 0.00037416 0.00038061 0.00030766 0.00027404\n",
      " 0.00051737 0.00030766 0.00027418 0.00045968 0.00408266 0.00030766\n",
      " 0.00075966 0.00032884 0.00042548 0.00027211 0.00062536 0.00028878\n",
      " 0.00049476 0.00027596 0.00027404 0.00027211 0.00027211 0.00036189\n",
      " 0.00027049 0.00027418 0.00028041 0.00041421 0.00027934 0.05402438\n",
      " 0.00027418 0.00037416 0.00033317 0.00027383 0.00027383 0.00037416\n",
      " 0.00037416 0.00433647 0.00030766 0.00027383 0.00027404 0.0013076\n",
      " 0.00054843 0.00027418 0.00037408 0.00030766 0.00029143 0.00028112\n",
      " 0.00031318 0.00036412 0.00027418 0.00027618 0.00031686 0.00027211\n",
      " 0.00029121 0.00027418 0.00027383 0.00033317 0.00040125 0.00032628\n",
      " 0.00037408 0.00027934 0.00027418 0.00027418 0.00027404 0.00027211\n",
      " 0.00027211 0.00027211 0.00027211 0.00049611 0.00027418 0.00027618\n",
      " 0.00029121 0.00037416 0.00120833 0.00027383 0.00087125 0.00037416\n",
      " 0.00038473 0.00030766 0.00027211 0.00056131 0.00027211 0.00046993\n",
      " 0.00034899 0.00027418 0.00027934 0.00027211 0.00027211 0.00036985\n",
      " 0.0013503  0.00029121 0.00028878 0.00027383 0.00027211 0.00027211\n",
      " 0.00027404 0.00027211 0.02948722 0.00087125 0.00027383 0.00027634\n",
      " 0.04747825 0.00065585 0.00077889 0.00030766 0.00027404 0.00391899\n",
      " 0.00030766 0.00027934 0.00029032 0.00027418 0.00186319 0.00032628\n",
      " 0.00027418 0.00027211 0.00040477 0.00027404 0.00030766 0.00037416\n",
      " 0.00027418 0.00037408 0.00045553 0.00027211 0.0004527  0.00104093\n",
      " 0.00029225 0.00027211 0.00033366 0.00037416 0.00027404 0.00034045\n",
      " 0.00054198 0.00037416 0.00030965 0.00027383 0.00045248 0.00027404\n",
      " 0.00027383 0.00027934 0.00057946 0.00027211 0.00045248 0.00027418\n",
      " 0.00027211 0.00038061 0.01552467 0.00027211 0.00046356 0.00027211\n",
      " 0.00376909 0.0010342  0.04747825 0.00027211 0.00030766 0.00029225\n",
      " 0.03224283 0.00029567 0.00037416 0.00027418 0.00027211 0.00037408\n",
      " 0.00032628 0.00027418 0.00037416 0.00037416 0.00029143 0.00027418\n",
      " 0.00041621 0.00054843 0.00029143 0.00027211 0.00027211 0.00335035\n",
      " 0.00027566 0.00055371 0.00054843 0.00037416 0.00039799 0.00027418\n",
      " 0.00027418 0.00027211 0.00037416 0.00027418 0.00027596 0.00027418\n",
      " 0.00027211 0.00027418 0.00147023 0.00027404 0.00037416 0.00027211\n",
      " 0.00029143 0.00027418 0.00985429 0.00027404 0.00030766 0.00049476\n",
      " 0.00027418 0.00027383 0.00027383 0.00027418 0.00027211 0.00027418\n",
      " 0.00027418 0.00060024 0.00134605 0.00027418 0.00029143 0.00027211\n",
      " 0.0003481  0.04922408 0.00027211 0.00027418 0.00027634 0.00044831\n",
      " 0.00027383 0.00029143 0.00037416 0.00030965 0.00030965 0.00028112\n",
      " 0.00027404 0.00058268 0.00035621 0.00027211 0.00032471 0.00037416\n",
      " 0.00037416 0.00083879 0.00027211 0.00034204 0.00033317 0.0003481\n",
      " 0.00027404 0.00045248 0.00077889 0.00045332 0.00128425 0.00027049\n",
      " 0.00052268 0.00087125 0.00027211 0.00037416 0.00029143 0.00027618\n",
      " 0.00042214 0.00306069 0.00027211 0.00031344 0.00027383 0.00036412\n",
      " 0.00037416 0.00045248 0.00033366 0.00037416 0.00027404 0.00027418\n",
      " 0.00064248 0.00030766 0.00077889 0.00083792 0.00027404 0.00037416\n",
      " 0.0229751  0.00087125 0.00027211 0.00027211 0.00027934 0.00083792\n",
      " 0.00030006 0.00027404 0.00027404 0.00027049 0.00027049 0.00030766\n",
      " 0.00036749 0.00027418 0.00027418 0.00155957 0.00030766 0.00030766\n",
      " 0.00130381 0.00030766 0.00071697 0.00027383 0.00037416 0.00027404\n",
      " 0.00038809 0.00027211 0.00027404 0.00033317 0.00027211 0.00079523\n",
      " 0.00027049]\n",
      "time cost 3.729158639907837\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_5_list\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_5_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "9.761824045171674e-05\n",
      "1228\n",
      "[3.14080521e-05 3.89500000e-05 2.66436158e-04 ... 7.69410170e-04\n",
      " 3.32547444e-04 2.78054235e-04]\n",
      "time cost 105.29113173484802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_6_list\n",
    "Damping_factor = 0.15\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"graph_6_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = {}\n",
    "for idx, x in enumerate(all_frequent_pattern.keys()):\n",
    "    node_list[x] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "4.5179538432954264e-05\n",
      "171\n",
      "[0.00479122 0.00583268 0.00583268 0.00479122 0.00479122 0.00537928\n",
      " 0.00537928 0.00537928 0.00537928 0.00537928 0.00537928 0.00329418\n",
      " 0.00357251 0.00295115 0.00384807 0.00384807 0.00384807 0.00448954\n",
      " 0.00329418 0.00257913 0.00340078 0.00340078 0.00287893 0.00287893\n",
      " 0.00447731 0.00656753 0.00504538 0.00504538 0.00504538 0.00702989\n",
      " 0.00257913 0.00540594 0.00540594 0.00400406 0.00446947 0.00993803\n",
      " 0.01023024 0.00847894 0.00960319 0.00859147 0.01068369 0.01836931\n",
      " 0.0060343  0.01065305 0.00673568 0.02149602 0.0123587  0.01326158\n",
      " 0.01484455 0.02478219 0.00804438 0.01065305 0.01906937 0.02528434\n",
      " 0.02557363 0.02249163 0.00287893 0.00257913 0.00487766 0.00321356\n",
      " 0.00509426 0.0035871  0.0035871  0.00600868 0.00393788 0.00287893\n",
      " 0.00287893 0.00287893 0.00441129 0.00257913 0.0035871  0.0035871\n",
      " 0.00321356 0.00754109 0.00462198 0.00540594 0.00446947 0.00540594\n",
      " 0.00400406 0.0063919  0.00658886 0.00798595 0.00994753 0.0117904\n",
      " 0.01029018 0.003626   0.0035871  0.0035871  0.0035871  0.0035871\n",
      " 0.00321356 0.00563562 0.00700776 0.00507742 0.00564698 0.00540594\n",
      " 0.00936769 0.00400406 0.00540594 0.00908733 0.01009943 0.00758517\n",
      " 0.00446947 0.00446947 0.00546004 0.00540594 0.00569396 0.00993684\n",
      " 0.00540594 0.00936057 0.01144493 0.00939669 0.01232635 0.00959801\n",
      " 0.00546004 0.00287893 0.00426295 0.00287893 0.00287893 0.00257913\n",
      " 0.00257913 0.00287893 0.00287893 0.00287893 0.0046541  0.0035871\n",
      " 0.003626   0.0035871  0.0035871  0.00321356 0.00548024 0.0035871\n",
      " 0.00548672 0.00558797 0.00624702 0.00287893 0.00287893 0.00287893\n",
      " 0.00287893 0.00496045 0.0035871  0.00601431 0.00321356 0.0035871\n",
      " 0.0035871  0.003626   0.00606795 0.0035871  0.003626   0.00650076\n",
      " 0.00664203 0.00596926 0.0035871  0.0035871  0.003626   0.00257913\n",
      " 0.00257913 0.00287893 0.00287893 0.00287893 0.00287893 0.00467768\n",
      " 0.00257913 0.00287893 0.00287893 0.00287893 0.00287893 0.00287893\n",
      " 0.00287893 0.00257913 0.00257913]\n",
      "time cost 2.963791847229004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = IBM_list\n",
    "Damping_factor = 0.15\n",
    "\n",
    "\n",
    "# def find_dim(wnat_list):\n",
    "#     dim = np.max(want_list)\n",
    "#     return dim\n",
    "\n",
    "# dim = int(float(find_dim(want_list)[0]))\n",
    "dim = len(node_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "\n",
    "# 建hub_matrix\n",
    "for idx,transaction in enumerate(want_list):\n",
    "    if (len(transaction[0]) != 1):\n",
    "        x_location = node_list[tuple(transaction[0])]\n",
    "    elif len(transaction[1]) != 1:\n",
    "#         print(transaction, len(transaction[0]), len(transaction[1]))\n",
    "        y_location = node_list[tuple(transaction[1])]\n",
    "    else:\n",
    "        x_location = node_list[transaction[0][0]]\n",
    "        y_location = node_list[transaction[1][0]]\n",
    "    \n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "        np.savetxt(f\"IBM_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# static_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = 0.15\n",
      "0.0001\n",
      "11\n",
      "time cost 0.001951456069946289\n"
     ]
    }
   ],
   "source": [
    "print(f\"D = {Damping_factor}\")\n",
    "print(want_threshold_error)\n",
    "# print(new_pagerank)\n",
    "print(times_graph_2)\n",
    "print(f'time cost {spend_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = 0.15\n",
      "11\n",
      "8.171056820782674e-05\n",
      "4\n",
      "[0.1754325 0.3245675 0.3245675 0.1754325]\n",
      "time cost 0.001951456069946289\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "want_threshold_error = 0.0001\n",
    "want_list = graph_3_list\n",
    "Damping_factor = 0.15\n",
    "\n",
    "def find_dim(wnat_list):\n",
    "    all_number_list = []\n",
    "    for x in want_list:\n",
    "        for num in x:\n",
    "            all_number_list.append(int(num))\n",
    "    dim = max(all_number_list)\n",
    "    return dim\n",
    "\n",
    "dim = find_dim(want_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "\n",
    "\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "# 建hub_matrix\n",
    "for idx, hub_point in enumerate(want_list):\n",
    "    y_location = int(hub_point[0]) - 1\n",
    "    x_location = int(hub_point[1]) - 1\n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "    \n",
    "    \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):#取零只是我想找len隨意設的\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                current_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) + (1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        \n",
    "        print(f\"D = {Damping_factor}\")\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "#         np.savetxt(f\"graph_1_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "8.319557731933675e-05\n",
      "171\n",
      "[0.00461867 0.00586995 0.00586995 0.00461867 0.00461867 0.00534313\n",
      " 0.00534313 0.00534313 0.00534313 0.00534313 0.00534313 0.00268039\n",
      " 0.00294304 0.00234178 0.00330108 0.00330108 0.00330108 0.00393449\n",
      " 0.00268039 0.00197    0.00282375 0.00282375 0.00225484 0.00225484\n",
      " 0.00431648 0.00684422 0.00504412 0.00504412 0.00504412 0.0074112\n",
      " 0.00197    0.00485683 0.00485683 0.0033812  0.0038701  0.01077752\n",
      " 0.01139085 0.00885989 0.01042105 0.0090771  0.01214023 0.02330287\n",
      " 0.0055591  0.01081986 0.00636291 0.02800603 0.01453482 0.01531782\n",
      " 0.01802669 0.0324748  0.00785275 0.01081986 0.02383426 0.03387743\n",
      " 0.03474033 0.02892242 0.00225484 0.00197    0.00440333 0.00258088\n",
      " 0.0045721  0.00295406 0.00295406 0.00545094 0.00332596 0.00225484\n",
      " 0.00225484 0.00225484 0.00396918 0.00197    0.00295406 0.00295406\n",
      " 0.00258088 0.00766217 0.00431558 0.00485683 0.0038701  0.00485683\n",
      " 0.0033812  0.00609588 0.00655957 0.00822234 0.01049402 0.01247933\n",
      " 0.01100171 0.0030012  0.00295406 0.00295406 0.00295406 0.00295406\n",
      " 0.00258088 0.00519571 0.00683308 0.00458284 0.00535611 0.00485683\n",
      " 0.01007346 0.0033812  0.00485683 0.00937597 0.01051973 0.00756603\n",
      " 0.0038701  0.0038701  0.00492752 0.00485683 0.00522397 0.01086631\n",
      " 0.00485683 0.00974036 0.01197956 0.00995393 0.01408475 0.00991283\n",
      " 0.00492752 0.00225484 0.00362658 0.00225484 0.00225484 0.00197\n",
      " 0.00197    0.00225484 0.00225484 0.00225484 0.00409409 0.00295406\n",
      " 0.0030012  0.00295406 0.00295406 0.00258088 0.00496316 0.00295406\n",
      " 0.00498551 0.00520953 0.00565    0.00225484 0.00225484 0.00225484\n",
      " 0.00225484 0.00440437 0.00295406 0.00557253 0.00258088 0.00295406\n",
      " 0.00295406 0.0030012  0.00558764 0.00295406 0.0030012  0.00628707\n",
      " 0.00603336 0.00548418 0.00295406 0.00295406 0.0030012  0.00197\n",
      " 0.00197    0.00225484 0.00225484 0.00225484 0.00225484 0.00396393\n",
      " 0.00197    0.00225484 0.00225484 0.00225484 0.00225484 0.00225484\n",
      " 0.00225484 0.00197    0.00197   ]\n",
      "time cost 3.490115165710449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "want_threshold_error = 0.0001\n",
    "want_list = IBM_list\n",
    "Damping_factor = 0.1\n",
    "\n",
    "\n",
    "# def find_dim(wnat_list):\n",
    "#     dim = np.max(want_list)\n",
    "#     return dim\n",
    "\n",
    "# dim = int(float(find_dim(want_list)[0]))\n",
    "dim = len(node_list)\n",
    "adj_matrix_hub = np.zeros((dim, dim))\n",
    "last_pagerank = np.ones(dim)/dim\n",
    "\n",
    "# 建hub_matrix\n",
    "for idx,transaction in enumerate(want_list):\n",
    "    if (len(transaction[0]) != 1):\n",
    "        x_location = node_list[tuple(transaction[0])]\n",
    "    elif len(transaction[1]) != 1:\n",
    "#         print(transaction, len(transaction[0]), len(transaction[1]))\n",
    "        y_location = node_list[tuple(transaction[1])]\n",
    "    else:\n",
    "        x_location = node_list[transaction[0][0]]\n",
    "        y_location = node_list[transaction[1][0]]\n",
    "    \n",
    "    adj_matrix_hub[y_location][x_location] += 1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "adj_matrix_authority = adj_matrix_hub.transpose()\n",
    "times_graph_2 = 0    \n",
    "while True:    \n",
    "    times_graph_2 += 1\n",
    "    new_pagerank = []\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(len(adj_matrix_authority)): #i代表當前再算那個node\n",
    "        \n",
    "        \n",
    "        parent_idx =[]\n",
    "        \n",
    "        #找parent outlink\n",
    "        for idx in range(len(adj_matrix_authority[0])):\n",
    "            if adj_matrix_authority[i][idx] != 0:\n",
    "                parent_idx.append(idx)\n",
    "        if len(parent_idx) == 0:\n",
    "            sum_parent_pagelink = 0\n",
    "        else:\n",
    "            sum_parent_pagelink = 0\n",
    "            for idx in parent_idx:\n",
    "                out_links = 0\n",
    "                parent_outlinks_list = adj_matrix_hub[idx]\n",
    "                for out_link in current_outlinks_list:\n",
    "                    if out_link != 0:\n",
    "                        out_links += 1\n",
    "                sum_parent_pagelink += last_pagerank[idx]/out_links\n",
    "        page_rank_damping = (Damping_factor/dim) +(1-Damping_factor) * sum_parent_pagelink\n",
    "        new_pagerank.append(page_rank_damping)\n",
    "        \n",
    "    new_pagerank_value = sum(np.absolute(new_pagerank))\n",
    "    last_pagerank_value = sum(np.absolute(last_pagerank))\n",
    "    new_pagerank = new_pagerank/new_pagerank_value\n",
    "    last_pagerank_nomalize = last_pagerank/last_pagerank_value\n",
    "    dif_pagerank = sum(np.absolute(new_pagerank - last_pagerank_nomalize)) \n",
    "    \n",
    "    if dif_pagerank < want_threshold_error:\n",
    "        print(f'{times_graph_2}')\n",
    "        print(dif_pagerank)\n",
    "        print(len(new_pagerank))\n",
    "        print(new_pagerank)\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time \n",
    "        print(f'time cost {spend_time}')\n",
    "#         np.savetxt(f\"IBM_PageRank_D={Damping_factor}.txt\", new_pagerank, newline = ' ', fmt = '%10.5f')\n",
    "        break\n",
    "    \n",
    "    last_pagerank = new_pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_pagerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(3):\n",
    "    t = 0\n",
    "    while True:\n",
    "        t +=1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
