{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def get_free_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    return np.argmax(memory_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(x, y, batch_size=32, shuffle=True, drop_last=True, device=torch.device('cpu')):\n",
    "    dataset = torch.utils.data.TensorDataset(x.to(device), y.to(device))\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_data(path, tokenizer, all_labels, max_len=512):\n",
    "    label2idx = {ele:idx for idx, ele in enumerate(all_labels)}\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        all_lines = [line.strip().split('\\t') for line in f]        \n",
    "        \n",
    "    for (text, label, aid, sid) in all_lines:\n",
    "        padding_len = max_len - 2 - len(label.split())\n",
    "        curr_x = tokenizer.encode(text, pad_to_max_length=True, truncation=True, max_length=max_len)\n",
    "        curr_y = [label2idx['X']] + [label2idx[l] for l in label.split()] + [label2idx['X']] + [label2idx['X']]*padding_len\n",
    "        x.append(curr_x)\n",
    "        y.append(curr_y)\n",
    "        \n",
    "    return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, te_x, te_y, batch_size=32):\n",
    "    warnings.filterwarnings(action='once')\n",
    "    test_dataloader = data_loader(te_x, te_y, batch_size=batch_size, shuffle=False, drop_last=False, device=avail_device)\n",
    "    all_pred = []\n",
    "    all_real = []\n",
    "    model.eval()\n",
    "\n",
    "    for batch_iter, (_x, _) in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(_x, labels=None)\n",
    "            curr_pred = torch.argmax(torch.softmax(outputs.logits.cpu().detach(), dim=-1), dim=-1).detach().numpy().tolist()\n",
    "            all_pred.extend(curr_pred)\n",
    "            all_real.extend(_.detach().cpu().numpy().tolist())\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(flat_classification_report(all_real, all_pred, labels=[i for i in range(2, len(all_labels))], target_names=all_labels[2:]))\n",
    "\n",
    "    return all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize from pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained = 'voidful/albert_chinese_xxlarge'\n",
    "#pretrained = 'bert-base-chinese'\n",
    "#pretrained = 'clue/roberta_chinese_base'\n",
    "#tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
    "\n",
    "#pretrained = 'distilbert-base-multilingual-cased'\n",
    "#pretrained = 'hfl/chinese-xlnet-base'\n",
    "#pretrained = 'hfl/chinese-electra-base-discriminator'\n",
    "pretrained = 'hfl/chinese-electra-large-discriminator'\n",
    "#tokenizer = AutoTokenizer.from_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElectraModel.from_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = ['X', 'O', 'B-time', 'I-time', 'B-med_exam', 'I-med_exam', 'B-name', 'I-name', 'B-location', 'I-location', \n",
    "              'B-family', 'I-family', 'B-ID', 'I-ID', 'B-clinical_event', 'I-clinical_event', 'B-profession', 'I-profession', \n",
    "              'B-education', 'I-education', 'B-money', 'I-money', 'B-contact', 'I-contact', 'B-organization', 'I-organization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = AlbertConfig.from_pretrained(\n",
    "#            pretrained,\n",
    "#            architectures=[\"AlbertForTokenClassification\"],\n",
    "#            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "#            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "#            num_labels=len(all_labels),\n",
    "#            return_dict=True\n",
    "#)\n",
    "\n",
    "#config = BertConfig.from_pretrained(\n",
    "#            pretrained,\n",
    "#            architectures=[\"bertForTokenClassification\"],\n",
    "#            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "#            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "#            num_labels=len(all_labels),\n",
    "#            return_dict=True\n",
    "#)\n",
    "\n",
    "#config = RobertaConfig.from_pretrained(\n",
    "#            pretrained,\n",
    "#            architectures=[\"RobertaForTokenClassification\"],\n",
    "#            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "#            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "#            num_labels=len(all_labels),\n",
    "#            return_dict=True\n",
    "#)\n",
    "\n",
    "#config = DistilBertConfig.from_pretrained(\n",
    "#            pretrained,\n",
    "#            architectures=[\"distilbertForTokenClassification\"],\n",
    "#            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "#            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "#            num_labels=len(all_labels),\n",
    "#            return_dict=True\n",
    "#)\n",
    "\n",
    "#config = XLNetConfig.from_pretrained(\n",
    "#            pretrained,\n",
    "#            architectures=[\"XLNetForTokenClassification\"],\n",
    "#            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "#            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "#            num_labels=len(all_labels),\n",
    "#            return_dict=True,\n",
    "#            mem_len=1024\n",
    "#)\n",
    "\n",
    "config = ElectraConfig.from_pretrained(\n",
    "            pretrained,\n",
    "            architectures=[\"ElectraForTokenClassification\"],\n",
    "            id2label={idx:ele for idx, ele in enumerate(all_labels)},\n",
    "            label2id={ele:idx for idx, ele in enumerate(all_labels)},\n",
    "            num_labels=len(all_labels),\n",
    "            return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_device = torch.device(\"cuda:{}\".format(get_free_gpu()) if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(pretrained, config=config).to(avail_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_grouped_parameters = [\n",
    "#    {'params': [p for n, p in model.named_parameters() if 'classifier' not in n], 'lr': 3e-5},\n",
    "#    {'params': [p for n, p in model.named_parameters() if 'classifier' in n], 'lr': 1e-3}\n",
    "#]\n",
    "#optimizer = AdamW(optimizer_grouped_parameters)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = None#torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1 / (1 + 0.002 * epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "batch_size = 8\n",
    "accumulation_steps = 1\n",
    "\n",
    "x, y = get_tensor_data('TEA/train_data_char_sub_510.txt', tokenizer, all_labels, max_len=max_len)\n",
    "train_dataloader = data_loader(x, y, batch_size=batch_size, shuffle=True, drop_last=True, device=avail_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "print_percent = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('===== epoch {} ====='.format(i+1))\n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    n_iters = len(train_dataloader)\n",
    "    print_every = n_iters*print_percent/100\n",
    "    print_every = 1 if print_every < 1 else int(print_every)\n",
    "    print_loss_total = 0\n",
    "    \n",
    "    for batch_iter, (_x, _y) in enumerate(train_dataloader):\n",
    "        outputs = model(_x, labels=_y)\n",
    "        outputs.loss = outputs.loss / accumulation_steps\n",
    "        print_loss_total += outputs.loss.item()\n",
    "        outputs.loss.backward()\n",
    "        \n",
    "        if (batch_iter+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                print(f'curr_lr: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]}')\n",
    "    \n",
    "        if (batch_iter+1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, (batch_iter+1)/n_iters),\n",
    "                                         (batch_iter+1), (batch_iter+1)/n_iters * 100, print_loss_avg))\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    evaluation(model, x, y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_x, te_y = get_tensor_data('TEA/dev_data_char_sub_510.txt', tokenizer, all_labels, max_len=max_len)\n",
    "test_dataloader = data_loader(te_x, te_y, batch_size=16, shuffle=False, drop_last=False, device=avail_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = []\n",
    "model.eval()\n",
    "\n",
    "for batch_iter, (_x, _) in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(_x, labels=None)\n",
    "        curr_pred = torch.argmax(torch.softmax(outputs.logits.cpu().detach(), dim=-1), dim=-1).detach().numpy().tolist()\n",
    "        all_pred.extend(curr_pred)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate result tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TEA/dev_data_char_sub_510.txt', 'r', encoding='utf8') as f:\n",
    "    test_lines = [line.strip().split('\\t') for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_test_lines = []\n",
    "combine_test_pred = []\n",
    "\n",
    "curr_line = []\n",
    "curr_pred = []\n",
    "curr_aid = 0\n",
    "\n",
    "for i in range(len(test_lines)):\n",
    "    article, _, aid, sid = test_lines[i]\n",
    "    \n",
    "    if int(aid) != curr_aid:\n",
    "        combine_test_lines.append(curr_line)\n",
    "        combine_test_pred.append(curr_pred)\n",
    "        curr_line = []\n",
    "        curr_pred = []\n",
    "        curr_aid += 1\n",
    "       \n",
    "    curr_line.extend(article.split())\n",
    "    curr_pred.extend(all_pred[i][1:-1][:len(article.split())])    \n",
    "    assert len(curr_line) == len(curr_pred)\n",
    "    \n",
    "if len(curr_line) and len(curr_pred):\n",
    "    combine_test_lines.append(curr_line)\n",
    "    combine_test_pred.append(curr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_tsv = [['article_id', 'start_position', 'end_position', 'entity_text', 'entity_type']]\n",
    "\n",
    "for aid in range(len(combine_test_lines)):\n",
    "    curr_line = combine_test_lines[aid]\n",
    "    curr_pred = combine_test_pred[aid]\n",
    "\n",
    "    entity_idxs = []\n",
    "    entity_text = []\n",
    "    entity_type = None\n",
    "\n",
    "    for i in range(len(curr_line)):\n",
    "        curr_text = curr_line[i]\n",
    "        curr_pred_token = curr_pred[i]\n",
    "        curr_prefix, *curr_type = all_labels[curr_pred_token].split('-')\n",
    "\n",
    "        ### curr state ###\n",
    "        if curr_prefix == 'B':\n",
    "            entity_idxs.append(i)\n",
    "            entity_text.append(curr_text)\n",
    "            entity_type = curr_type[0]\n",
    "\n",
    "        elif curr_prefix == 'I':\n",
    "            entity_idxs.append(i)\n",
    "            entity_text.append(curr_text)\n",
    "\n",
    "        ### next state ###\n",
    "        if i == len(curr_line)-1:\n",
    "            if len(entity_idxs) and len(entity_text) and entity_type is not None:\n",
    "                upload_tsv.append([str(aid), str(entity_idxs[0]), str(entity_idxs[-1]+1), ''.join(entity_text), entity_type])\n",
    "        else:\n",
    "            next_pred_token = curr_pred[i+1]\n",
    "            next_prefix, *next_type = all_labels[next_pred_token].split('-')\n",
    "\n",
    "            if next_prefix in {'O', 'X', 'B'} or (next_prefix == 'I' and next_type[0] != entity_type):\n",
    "                ### update ###\n",
    "                if len(entity_idxs) and len(entity_text) and entity_type is not None:\n",
    "                    upload_tsv.append([str(aid), str(entity_idxs[0]), str(entity_idxs[-1]+1), ''.join(entity_text), entity_type])\n",
    "\n",
    "                ### reset ###\n",
    "                if next_prefix in {'O', 'X', 'B'}:\n",
    "                    entity_idxs = []\n",
    "                    entity_text = []\n",
    "                    entity_type = None\n",
    "                else:\n",
    "                    entity_idxs = [i]\n",
    "                    entity_text = [curr_text]\n",
    "                    entity_type = next_type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./bert_pytorch_rebuild_result/baseline_3.tsv', 'w', encoding='utf8') as f:\n",
    "#    f.write('\\n'.join(['\\t'.join(l) for l in upload_tsv]))\n",
    "\n",
    "#with open('./bert_pytorch_rebuild_result/baseline_9_e40.tsv', 'w', encoding='utf8') as f:\n",
    "#    f.write('\\n'.join(['\\t'.join(l) for l in upload_tsv]))\n",
    "\n",
    "with open('./bert_pytorch_rebuild_result/baseline_10_e30.tsv', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(['\\t'.join(l) for l in upload_tsv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recorded\n",
    "\n",
    "1. baseline_0 = bert-base-chinese / tf / max_len 512 / batch 4 / lr 3e-5 / 100 epoch\n",
    "2. baseline_1 = bert-base-chinese / tf / max_len 128 / batch 16 / lr 2e-5 / 100 epoch\n",
    "3. baseline_2 = bert-base-chinese / huggingface / max_len 512 / batch 4 / lr 2e-5 / 40 epoch / lr 1e-5 / 20 epoch /\n",
    "4. baseline_3 = bert-base-chinese / huggingface / max_len 512 / batch 4 / lr 2e-5 / 40 epoch / lr 1e-5 / 20 epoch / + chinese   number convert\n",
    "\n",
    "\n",
    "\n",
    "10. baseline_9_e20 = distilbert-base-multilingual-case / max_len 512 / batch 4 / lr 5e-6 / 20 epoch\n",
    "10. baseline_9_e40 = distilbert-base-multilingual-case / max_len 512 / batch 4 / lr 2e-6 / 20 ~ 40 epoch\n",
    "\n",
    "\n",
    "11. baseline_10_e20 = electra-base / max_len 512 / batch 8 / lr 1e-4 / 20 epoch\n",
    "11. baseline_10_e30 = electra-base / max_len 512 / batch 8 / lr 1e-4 / 30 epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
